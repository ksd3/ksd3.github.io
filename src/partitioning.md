# An annotated explanation of 'A gas rich cosmic web revealed by partitioning the missing baryons' by Connor et al. (2024)

## About

Connor et al. (2024) recently published a [paper](https://arxiv.org/html/2409.16952v1) that shows a way to partition the universe's baryons to reveal the underlying [cosmic web](https://science.nasa.gov/resource/cosmic-web/) structure and showed that it contains a lot of gas. Is it possible to explain this paper to mildly intelligent people with an interest in astronomy?

### Abstract
Approximately half of the universe's dark matter (that is, matter that does not interact with electromagnetic radiation such as light, so we can't see it) resides in structures known as 'collapsed halos'. Collapsed halos are ellipsoidal or quasi-spherical structures surrounding a central object like a star. The initial universe's density field was approximately uniform, but quantum fluctuations led to changes in the initial density field at different points. Changes in density eventually led to gravity taking over and clustering the matter into halo-like structures. Significantly less than half of the universe's baryons (protons and neutrons; electrons are leptons because they interact only using the weak nuclear force and the electromagnetic force) are confined to halos. A small fraction of the baryons are present as stars and in the interstellar medium (ISM) between galaxies. A lot of them are very diffuse (less than 1000 per cubic centimeter) and ionized (less than one in ten thousand is ionized in the baryonic gas) and are located in the halos of galaxy clusters, galaxy groups (literally just some galaxies together but not enough to be a cluster), or individual galaxies. Because this gas is so diffuse and ionized, the quantity and spatial distribution is very difficult to measure. If we measure it really well and are able to provide an accurate answer to the question 'what is this quantity and spatial distribution?' then we have an answer to a lot of important questions in galaxy formation, astrophysical feedback (the ejection of matter by stars, black holes, etc into the universe, or the reverse!), and precision cosmology. Recently, people have used Fast Radio Bursts (FRBs), very violent emissions of radio waves first discovered in 2007, to measure the total content of cosmic baryons. The problem in those studies is that they did not contain methods to discriminate between the intergalactic material (IGM) and halo gases. In this paper we present a large cosmological sample of FRB sources localized to their host galaxies. Also we have managed to partition (that is, determine the distribution of) missing baryons into the IGM, galaxy clusters, and galaxies. As a reminder, the term missing baryons refers to the following problem: cosmological models say that the number of baryons in the universe should be so-and-so, but actual measurements show that there are much fewer baryons. Then where are the missing baryons? The study provides a late-Universe (that is, the current universe) measurement of the total baryon density of $\Omega_{b}â€‹h_{70}$ as 0.049 $\pm$0.003, where $\Omega_{b}$ is the universe's critical density (the density needed for a flat universe) that is made of baryonic matter. $h_{70}$ is simply a scaling factor related to the Hubble constant. The results indicate that feedback processes can expel gas from galaxy halos and into the intergalactic medium, agreeing with the enriched cosmic web scenario (that is, how the cosmic web contains elements heavier than hydrogen and helium) seen in cosmological simulations. We measured a large diffuse baryon fraction and that probably means that the distribution of stellar masses in a population of stars (the initial stellar mass function) is probably not bottom-heavy (it does not predict a large number of low mass stars, which in turn live for longer).

### Introduction

The Deep Synoptic Array-110 is a radio inteferometer (a system of radio telescopes that observe the same source at the same time) operating between 1.28-1.53 GHz and is the first radio telescope built to detect and localize FRBs (that is, find out the galaxy they originate from). Doing this helps use FRBs as cosmological tools and unveil their physical origin. 60 new FRBs were discovered by DSA-110 and 39 of them now have an associated host galaxy spectroscopic redshift. Our companion work shows the properties of the host galaxies of a uniformly selected subset of these. The work also includes 9 sources not in that sample. Three new FRBs near or beyond redshift 1 (redshift 1 means ~8-9 billion years old, as the wavelength of light has doubled) are also presented. Because these FRBs are at redshift 1, they constrain the IGM column (that is, the distribution of material along the line of sight) by virtue of their great distance. 

We add our sample to 30 previously localized FRB sources. The distribution of extragalactic DM (dispersion measure - the TEC, but measured in terms of redshift) and redshift for the full sample is plotted in figure 1; the positions, DM, redshifts, and detection instruments are displayed in extended data table 1. The extragalactic DM of localized FRBs tells us how many diffuse baryons are in what place in the Universe. The total observed DM of an FRB can be split into several components. Let's take a moment to think about this. When looking at a radio source occurring so far away, we need to consider several things. First, we are looking out of the Milky Way, so the Milky Way's ISM contributes to the total DM. The Milky Way's halo also contributes to it. The inter _galactic_ medium along the line of sight is of course always present. There is also some ionized gas in stable halos (_virialized_ halos). Then there are also the contributions from each ionized halo along the line of sight. To account for the expansion of the universe and relativistic motion the factor $\frac{1}{1+z_{halo}}$ is applied to the observed dispersion measure. Finally there is the contribution of the FRB host galaxy's matter (note that since we are now talking about plasmas, it means that we must consider fermionic matter such as electrons too), which may come from its halo, ISM, or any other plasma lying around the galaxy. 

We can therefore write the observed FRB of a galaxy in the following way:
$$
DM_{obs}=DM_{MW}+DM_{IGM}(z_s)+\sum_{i}^{N_x}\frac{DM_X(M_i,b_{\perp})}{1+z_i}+\frac{DM_{host}}{1+z_s}
$$

Note that the $b_{\perp}$ term is the _physical impact parameter_, which is a measure of how close the line of sight passes to higher-mass regions in the intersecting halo. A higher $b_{\perp}$ means that the line of sight is on the outskirts of the matter distribution and vice versa. Also, the subscript $X$ just means intersection. DM_{IGM} generally dominates for sources beyond $z \approx 0.2$ unless the FRB is in an ununsual galaxy. Let us now define a 'cosmological DM' as $DM_{cos}\equiv DM_{X}+DM_{IGM}$. Our goal is to now find out what the average sightline's DM from the IGM and intervening halos would be.

---
#### Interlude: DM and TEC

The [Total Electron Content](https://en.wikipedia.org/wiki/Total_electron_content) is simply the columnar number density of electrons where the column is along a line of sight. It is obtained by integrating the electron density along a path $ds$: $$\int_{0}^{l}n_e(s)ds$$, where $l$ is the straight-line distance the radio source and the observer. It is a measure of how the underlying plasma interferes with radio signals passing through it.

The [dispersion measure](https://arxiv.org/pdf/2407.16748) is the exact same thing. It is a measure of how the intermediary plasma affects radio waves passing through it. The catch is that the DM is measured on galactic scales; we must take into account the effects of relativity. The dispersion measure is defined as $$\int_{0}^{z}n_e(z)dl$$, where $z$ is the **redshift** and $dl$ is the proper distance element. The proper distance is the actual distance between two objects in the universe at a certain point in cosmic time. What does this mean? We know the universe is expanding. If we want to measure the distance between two objects at a certain point in time, we simply freeze the universe and observe it from a god's-eye perspective. The proper distance is now the distance between the two objects. The proper distance is related to the _comoving distance_ by multiplying with a simple factor (called the scale factor), given the universe is described by the [FLRW metric](https://en.wikipedia.org/wiki/Friedmann%E2%80%93Lema%C3%AEtre%E2%80%93Robertson%E2%80%93Walker_metric).
The differential of the proper distance element is related to the [Hubble factor](https://en.wikipedia.org/wiki/Hubble%27s_law) and redshift by the equation $$dl=c\frac{dz}{H(z)}$$.

 Because of how the redshift is [defined](https://en.wikipedia.org/wiki/Redshift), the physical baryon density scales with redshift as $(1+z)^3$. The DM is therefore a redshift corrected version of the TEC. It is correct to use it when considering things on intergalactic scales, not on interstellar scales.

--- 

Since the DM is a measure of interference by electrons, we need to figure out how to relate this with baryons. We know that the number of protons and electrons are roughly the same in the universe. Of course, some of the baryons could be locked up in stars like neutrons in neutron stars; some of the protons could be flying around on their own without an electron to balance them. Let's relate our dispersion measure to baryons. First, let $f_d(z)$ be the fraction of all baryons lying in the diffuse ionized IGM or halos (not in stars, cold gas, and so on), and let $f_e(z)$ be the effective number of free electrons per baryon (if they're electrically neutral, how can they intefere with radio waves?). 

Then $$n_e(z)=f_d(z)f_e(z)$$. The proper baryon density at redshift $z$ scales as $(1+z)^3$, so you can write $$n_e(z)=f_d(z)f_e(z)\Omega_b \rho_{c,0} (1+z)^3/m_p$$

where $\Omega_b$ is the present-day baryon density parameter (the _cosmic baryon abundance_), $\rho_{c,0}=\frac{3H_0^2}{8\pi G}$ is the present [critical density](https://en.wikipedia.org/wiki/Friedmann_equations#Density_parameter) for a flat universe, and $m_p$ is the proton mass (so $\frac{\rho_{c,0}}{m_p}$ counts the number of baryons).

Therefore, $$n_e(z)=f_d(z)f_e(z)(\Omega_b\frac{3H_0^2}{8 \pi G}(1+z)^3)\frac{1}{m_p}$$.

The Hubble parameter at redshift $z$ for a spatially flat FRW universe with matter fraction $\Omega_m$ and cosmological constant (the _dark energy parameter_) $\Omega_{\Lambda}$ is $$H(z)=H_0 \sqrt{\Omega_m (1+z)^3+ \Omega_\Lambda}$$

and $dl=\frac{c}{H(z)}dz$, so $$dl=\frac{c}{H_0}\frac{dz}{\sqrt{\Omega_m (1+z)^3+ \Omega_\Lambda}}$$

Therefore the average sightline DM would be $$<DM_{cos}>=\frac{3c}{8\pi}\frac{\Omega_b}{G}\frac{H_0}{m_p} \int_{0}^{z_s}\frac{(1+z)f_d(z)f_e(z)}{\sqrt{\Omega_m (1+z)^3+ \Omega_\Lambda}}$$

where the extra $1+z$ in the denominator comes from how many factors in the group-delay integral you want to account for. 

We take $f_e=0.875$, $f_d$ as a constant, and $h_{70}\equiv H_0(70 km s^{-1} Mpc^{-1})$, $$<DM_{cos}> \approx 1085zf_d(\frac{\Omega_b h_{70}}{0/04703}) \frac{pc}{cm^3}$$ for $z_s \lesssim 1$.

For each FRB, we compute the extragalactic DM distribution $DM_{ext}=DM_{obs}-DM_{MW}$ as a function of the source redshift $z_s$. This means that we compute a 1D likelihood function $P(DM_{ex} | z_s, \vec{\theta})$, where the model parameters $\vec{\theta}$ are given by $\vec{\theta}=\{f_{IGM}, f_X, \mu_{host}, \sigma_{host}\}.$ Here $f_{IGM}$ is the fraction of baryons in the IGM ($\frac{\Omega_{IGM}}{\Omega_b}$) and $f_X=\frac{\Omega_{halos}}{\Omega_{b}}$ is the fraction of baryons in the intersected halos referenced (normalized) to redshift 0.1. Why can this be done? It's because the three components of the dispersion measure - $DM_{IGM}$,$DM_{X}$, and $DM_{MW}$ all have different dependencies on the redshift (their distributions $P(DM|z)$ are different) given a sufficiently large sample size. $\mu_{host}$ and $\sigma_{host}$ are the mean dispersion measure and scattering coefficient of the host galaxy of the source, respectively. Note that the IGM is defined as the gas outside of [virialized](https://en.wikipedia.org/wiki/Virial_theorem) (i.e. stable) dark matter halos. 

---
#### Interlude: Bayes' Theorem

Bayes' theorem allows one to compute the probability of a cause given its effect. Given a prior belief of the hypothesis (the **prior**), you update it with new data (the **likelihood**), and compute the probability of the cause given the effect (the **posterior probability** or **posterior**) according to the formula $$P(\theta|D)=\frac{P(D|\theta) P(\theta)}{P(D)}$$ where $P(\theta|D)$ is the posterior, $P(D|\theta)$ is the likelihood, $P(\theta)$ is the prior, and $P(D)$ is the **marginal likelihood** or **evidence** - the total probability of the effect itself occurring, considering all possible causes.

---

We want to find out the [joint distribution](https://en.wikipedia.org/wiki/Joint_probability_distribution) that describes the probability that $DM_{ex}$ is a certain value given a certain value of the redshift $z$. To do this, we compute the 1D likelihood function given above for each FRB, and multiply them together. ($\prod_{i}^{n}P(DM_{ex,i}|z_{s,i})P(\vec{\theta})$). To do this, we apply Markov Chain Monte Carlo (MCMC) methods.

---
#### Interlude: Markov Chain Monte Carlo (MCMC) methods:

Sampling from a probability distribution means randomly selecting points where the likelihood of selecting a given point is defined by the probability distribution. To sample from a one-dimensional probability distribution is easy - suppose someone said to you 'I have a Gaussian probability distribution with a mean of 3.5 and a standard deviation of 2. You can take as many numbers as you want and I'll give them to you. Since it is a normal distribution, you're more likely to get a bunch of numbers around 3.5; once you get a bunch of numbers you can compute how many fell between 3.2 and 3.63, 1.32 and 1.39, and so on'. You could simply get a bunch of numbers (say 3266 numbers) and run some tests on them and go 'okay, makes sense, I see that I have 299 numbers between 3.2 and 3.63 and 29 between 1.32 and 1.39. This is fairly reasonable'. The numbers you chose are **samples** of that probability distribution and you chose them one at a time. 

Then the person (let's say the ghost of your great grandfather) comes up to you and says 'I have a probability distribution defined as the convolution of the Riemann Zeta function and the Von Mangoldt function for 55681 variables, but the convolution is only computed at roots of the normal numbers between 4 and 48575'. You are stuck. How would you even go about sampling this distribution? You're not allowed to ask him to give you numbers, because even he doesn't want to compute things. This is where MCMC methods come in.

Let us focus on how MCMC methods broadly work. You want to sample from a probability distribution. Why do you want to do this? If you have enough samples then you can compute averages (more precisely, **expectation values**), answer probabilistic questions, or even just flat out plot it. You say, "Okay, let me start with an initial guess. For lack of a better guess, I'll start with a completely random guess. Then I look at points near to my guess and pick one. How? Let's just go with any random point near me. Then I decide whether to move in that direction or not. If yes, I move in that direction and repeat the procedure. Otherwise I pick another point. If I keep moving for long enough I will probably cover the whole probability distribution."

More precisely, given some underlying knowledge of the probability distribution, you can sample from it and construct a rough approximation of the actual probability distribution. This underlying knowledge may also be based on hunches: assume that at least, locally, the distribution is Gaussian. 

The process of getting this sample from the underlying knowledge is called a **Monte Carlo** method and the construction of a series of steps (a straightforward example of a **random walk**) is an example of generating a **Markov Chain**. The implicit assumption is that the next step only depends on your current state, so this is a first-order Markov chain.

---

What distribution do we assume for the host contribution to the dispersion measure? Let's go with a log-normal distribution, as it is right-skewed and defined only for positive values. We are going to estimate $\mu_{host}$ and $\sigma_{host}$. The prior values for $\mu_{host}$ are assumed to be from a uniform probability distribution between 0 and 7 (therefore the DM spans 0 to 1000 $pc\text{ }cm^{-3}$) and the same flat prior shape is used for $f_{IGM}$ and $f_{X}$, but the values range from 0 to 1. The added constraint is $f_{IGM}+f_X\leq 1$. 

Fitting this distribution to our dataset gives $f_{IGM}=0.80^{+0.08}_{-0.09}$ and $f_{X}=0.11^{+0.10}_{-0.07}$. We calculate that $\mu_{host}=4.90^{+0.18}_{-0.20}$ and $\sigma_{host}=0.56^{+0.16}_{-0.14}$. This means that the median rest-frame contribution of the host to the DM is $130^{+25}_{-23}\text{ } pc \text{ }cm^{-3}$ for our sample. We fit subsamples of the data (such as DSA-110 detected sources) and do jackknife resampling (such as leave-one-out and compute every sample, and compute each statistic for every sample set, and take the mean), and end up observing that sources with $z_s\gtrsim 0.5$ constrain the range of the parameters significantly. But our data prefer a large fraction of baryonic material in the IGm and a large total diffuse fraction $f_d$. This is probably because there are too few sources with low $DM_{ex}$ per unit redshift (called the **DM cliff**). As an example, none of our sources beyond redshift 0.1 has $\frac{DM_{ex}}{z_s}<800 \text{ }pc \text{ } cm^{-3}$. If the extragalactic DM was dominated by intervening halos or host galaxies then $P(DM_{ex} | z_s)$ would be smaller for low DMs because of the increased line-of-sight variance. Incidentally, this would be true for a universe where baryons perfectly trace the dark matter. But the IGM provides a significant statistical floor for DM per unit distance because most sightlines intersect dozens of filaments and even cosmic voids have a considerable electron column present. Our FRB sample rules out scenarios where baryons trace dark matter ($f_{IGM}$ is low and a large portion of missing baryons are confined to galaxy halos). 

Although FRB DMs are affected by ionized gas in galaxy groups and clusters, the most precise constraints on the baryon budget in massive halos come from X-ray and [SZ](https://en.wikipedia.org/wiki/Sunyaev%E2%80%93Zeldovich_effect) measurements. As a reminder, thermal X-ray emission is $\propto \int n_e^2dl$ and SZ is $\propto \int n_eT_edl$. This means that both measurements are sensitive to large, dense regions of hot gas. FRBs pick up DM from ionized plasmas in the way. The hot baryon fraction in halos ($f_{hot}$) is a function of halo mass, approaching the cosmological ratio $\approx \frac{\Omega_b}{\Omega_M}$ for most massive galaxy clusters. It should be noted that this quantity is less certain for halos below $10^{14} h_{70}^{-1}M_\odot$, but recent advances in sample sizes and measurement precision has significantly improved our knowledge of both the cluster mass function and $f_{hot}$. Combining these multiwavelength observations allows us to estimate the fraction of the universe's baryons in the hot gas of galaxy groups and clusters. We find $f_{ICM}=3.75 \pm 0.5\%$ of all baryons in the intracluster medium (ICM). For galaxy groups with $10^{12.7}M_{\odot} \leq M_h \leq 10^{14} M_{\odot}$ this number is $5.4 \pm 1.0 \%$ and therefore, a simple addition shows that roughly 9% of baryons are in a diffuse ionized state in massive halos.

What about the baryons in galaxies, including stars and cold gas? They are the last major group of baryons left. The majority of the cold gas is neutral atomic hydrogen (along with a little molecular hydrogen and helium). 21cm HI surveys at low redshifts measure the HI mass function which is then integrated to estimate the neutral hydrogen density. Taking $\Omega_{HI}, \Omega_{H_2}$ from recent surveys we find $f_{HI}=9.6^{+3.8}_{-2.3} \times 10^{-3}, f_{H_2}=1.6^{+0.8}_{-0.4} \times 10^{-3}, f_{cold}=1.1^{+0.3}_{-0.2} \times 10^{-2}$. This means just over one percent of the Universe's baryons are in cold neutral gas within galaxies. For stars estimating this fraction is significantly more difficult. The fraction itself is larger as well. Most stellar mass is in low-mass stars and we can easily see from earlier discussion that the choice of the initial mass function affects the baryon fraction $f_*$ quite a bit. The [Salpeter IMF](https://en.wikipedia.org/wiki/Initial_mass_function#Salpeter_(1955)) (bottom heavy) can return a value of 14%. Instead we can use the Chabrier IMF and a smooth fit to multiple measurements of the local stellar density to get about 4-7%. 

After all of this, we can fully account for the [missing baryons](https://en.wikipedia.org/wiki/Missing_baryon_problem) by combining the FRB results with other observations. We can also partition the baryons into the IGM, galaxy groups, galaxy clusters, and galaxies. A significant majority of baryonic matter resides in the IGM, outside of virialized halos. From the FRB-independent analysis X-ray groups and clusters, $9.2^{1.6}_{-1.6}\%$ are in an ionized phase occupying massive halos. Roughly one percent are in cold neutral gas in galaxies. The conclusion is that the circumgalactic medium (CGM) of individual galaxies cannot contain a substantial fraction of the baryons in the universe. This is in agreement with detailed studies of individual FRB source sightlines. Our FRBs that intersect one or more foreground galaxy CGM at low impact parameters do not have significant excess dispersion. We find $f_{gas}=0.22^{+0.23}_{-0.17} \frac{\Omega_b}{\Omega_M}$ for $10^9 M_\odot < M < 5 \times 10^{12} M_\odot$, below the cosmic average. 

What do these results mean? The first basic observation is that feedback processes are required to expel gas and/or prevent gas from falling into their potential wells. We cannot differentiate between specific methods but our conclusion of a rich IGM and baryon-deficient CGM is consistent with simulations where feedback suppresses lower-mass baryon halos. As a reminder, $f_{IGM}$ is about 0.8. This agrees with other simulations. In [SIMBA](http://simba.roe.ac.uk/) simulation with feedback turned off, $f_{IGM}\approx 0.6$ by $z<1$ and $>0.85$ with [AGN](https://en.wikipedia.org/wiki/Active_galactic_nucleus) feedback turned on. In the [IllustrisTNG](https://www.tng-project.org/) simulation $f_{IGM}\approx 0.8$ at low redshifts and baryons were missing from the CGM of Milky Way-like galaxies. Statistical cross-correlations of galaxy surveys with X-ray and kinematic SZ also agreed and showed that there were few baryons in galaxy halos.

So far we have shown that $f_{IGM}$ is high and agrees with simulations. Let's check if another method leads to the same answer. This other method should not rely on a partition of the cosmic baryons as the quantity is sensitive to both the intergalactic and intervening halo gas. To do this, we can use the average cosmic dispersion derived above. This results in $f_d=0.93^{+0.04}_{-0.05}$, independent of any assumptions about $P_{cos}(DM_{IGM}, DM_{X})$ and its redshift evolution. 

The mean cosmological DM of FRBs places a ceiling on the total stellar mass of the universe because $f_*<1-f_d-f_{cold}$. The results our our analysis suggest that over 90% of baryons are in a diffuse state in the IGM and in dark matter halos or cold gas (read: not in stars). This is independent of galaxy spectral energy distribution modeling, choice of the IMF, and the low mass cutoff for other methods. As we have repeatedly stated, most of the stellar mass is in numerous small stars. Our $f_*$ constrains the mean stellar IMF. We place a 90% upper limit on the stellar baryon fraction at low redshifts of $f\leq 9\%$ and therefore $\rho_* \leq 5.6 \times 10^8 M_\odot Mpc^{-3}$ and therefore Salpeter IMFs can be ruled out for a low-mass cutoff below 0.10 $M_\odot$.

If the Universe's total cosmic baryon content is made a free parameter then $\Omega_bh_{70}=0.049^{+0.004}_{-0.003}$. This measurement at a late time (remember that we are measuring at $h_{70}$) is consistent at the sub-10% level with early Universe constraints of the physical baryon density from Big Bang Nucleosynthesis and the CMB. An equally precise constraint can be obtained for the Hubble constant - $H_0=71^{+6}_{-6} km \text{ } s^{-1} \text{ } Mpc^{-1}$ with the caveat that disactually calculating this value $H_0$ from $\Omega_b$ requires fixing the baryon density parameter at the value it would be in the early universe. A possible future task could be cross-correlating a large sample of FRB DMs against other measurements that indicate the large-scale structure. This will enable even tighter bounds of some cosmological parameters and also allow measuring astrophysical feedback. 